# ===========================================
# AI Provider Configuration
# ===========================================
# Priority: OLLAMA_HOST > ANTHROPIC_API_KEY > OPENAI_API_KEY
# Leave cloud API keys empty to use Ollama (default)

# Ollama (Local LLM - default, no API key needed)
OLLAMA_HOST=http://ollama:11434
OLLAMA_MODEL=llama3.2

# Cloud providers (optional - uncomment to use instead of Ollama)
# OPENAI_API_KEY=sk-your-openai-key
# ANTHROPIC_API_KEY=sk-ant-your-anthropic-key
